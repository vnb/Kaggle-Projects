{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\nimport numpy as np\nimport pandas as pd\nimport re\nfrom sklearn import datasets, linear_model\nimport matplotlib.pyplot as plt\nfrom matplotlib.ticker import FuncFormatter\nimport tensorflow as tf\nfrom tensorflow import keras\nimport seaborn as sns\nimport scipy.stats as stats\nfrom collections import Counter\nfrom sklearn.model_selection import KFold\nfrom sklearn import preprocessing\npd.set_option(\"display.latex.repr\", True)\nimport xgboost as xgb\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"train_set = pd.read_csv('../input/train.csv')\ntest_set = pd.read_csv('../input/test.csv')\nids = test_set['Id']\ntrain_set.head(5)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"print (\"\\n\\n---------------------\")\nprint (\"TRAIN SET INFORMATION\")\nprint (\"---------------------\")\nprint (\"Shape of training set:\", train_set.shape, \"\\n\")\nprint (\"Column Headers:\", list(train_set.columns.values), \"\\n\")\n#print (train_set.describe(), \"\\n\\n\")\n#print (train_set.dtypes)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"print (\"\\n\\n--------------------\")\nprint (\"TEST SET INFORMATION\")\nprint (\"--------------------\")\nprint (\"Shape of test set:\", test_set.shape, \"\\n\")\nprint (\"Column Headers:\", list(test_set.columns.values), \"\\n\")\n#print (test_set.describe(), \"\\n\\n\")\n#print (test_set.dtypes)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"missing_values = []\nnonumeric_values = []\n\nprint (\"TRAINING SET INFORMATION\")\nprint (\"========================\\n\")\nmissing_values_set_train = []\nfor column in train_set:\n    # Find all the unique feature values\n    uniq = train_set[column].unique()\n    print (\"'{}' has {} unique values\" .format(column,uniq.size))\n    if (uniq.size > 25):\n        print(\"~~Listing up to 25 unique values~~\")\n    print (uniq[0:24])\n    print (\"\\n-----------------------------------------------------------------------\\n\")\n\n    # Find features with missing values\n    if (True in pd.isnull(uniq)):\n        s = \"{} has {} missing\" .format(column, pd.isnull(train_set[column]).sum())\n        missing_values_set_train.append(column)\n        missing_values.append(s)\n        \n    # Find features with non-numeric values\n    for i in range (1, np.prod(uniq.shape)):\n        if (re.match('nan', str(uniq[i]))):\n            break\n        if not (re.search('(^\\d+\\.?\\d*$)|(^\\d*\\.?\\d+$)', str(uniq[i]))):\n            nonumeric_values.append(column)\n            break\nnonumeric_values_train = nonumeric_values\nmissing_values_train = missing_values\nprint (\"\\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\\n\")\n#print (\"Features with missing values:\\n{}\\n\\n\" .format(missing_values))\n#print (\"Features with non-numeric values:\\n{}\" .format(nonumeric_values))\nprint (\"\\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\\n\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#sns.pairplot(train_df[col], size=3);\nplt.figure()\notl = sns.lmplot('GrLivArea', 'SalePrice',data=train_set, fit_reg=False);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_set.drop(train_set[(train_set['GrLivArea'] > 4000)].index,inplace=True)\n\nplt.figure()\nsns.lmplot('GrLivArea', 'SalePrice',data=train_set, fit_reg=False);\nplt.xlim(0,5500);\nplt.ylim(0,800000);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(train_set['SalePrice'])\nplt.title('SalePrice Distribution')\nplt.ylabel('Frequency')\n\nplt.figure()\nqq = stats.probplot(train_set['SalePrice'], plot=plt)\nplt.show()\n\n# For normally distributed data, the skewness should be about zero. \n# A skenewss  value greater than zero means that there is more weight in the left tail of the distribution\n\nprint(\"Skewness: {:.3f}\".format(train_set['SalePrice'].skew()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(25,5))\n\n# correlation table\ncorr_train = train_set.corr()\n\n# select top 10 highly correlated variables with SalePrice\nnum = 10\ncol = corr_train.nlargest(num, 'SalePrice')['SalePrice'].index\ncoeff = np.corrcoef(train_set[col].values.T)\n\n# heatmap\nheatmp = sns.heatmap(coeff, annot = True, xticklabels = col.values, yticklabels = col.values, linewidth=2,cmap='PiYG', linecolor='blue')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(train_set[col], size=3);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = train_set\nmc = pd.DataFrame(df.isnull().sum(),columns=['Missing Count'])\nmc = mc[mc['Missing Count']!=0]\nmc['Missing %'] = (mc['Missing Count'] / df.shape[0]) * 100\nmc.sort_values('Missing %',ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# seperate the target variable (SalePrice) from the train\n\ny_df = train_set['SalePrice']\ntrain_set.drop('SalePrice',axis=1,inplace=True)\n\nprint('dimension of the train:' , train_set.shape)\nprint('dimension of the test:' , test_set.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# In order to avoid repeating unnecessary codes, for our convenience, let's combine the train and test set.\ndf = pd.concat([train_set, test_set]).reset_index()\n\ndf.drop(['index'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('dimension of the dataset:' , df.shape)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mc = pd.DataFrame(df.isnull().sum(),columns=['Missing Count'])\nmc = mc[mc['Missing Count']!=0]\nmc['Missing %'] = (mc['Missing Count'] / df.shape[0]) * 100\nmc.sort_values('Missing %',ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nones = ['PoolQC', 'MiscFeature', 'Alley','Fence', 'FireplaceQu', 'GarageType','GarageFinish',\n        'GarageQual','GarageCond','BsmtQual','BsmtCond','BsmtExposure','BsmtFinType1','BsmtFinType2',\n        'MasVnrType']\n\nfor none in nones:\n    df[none].fillna('None',inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"zeros = ['GarageYrBlt','GarageArea','GarageCars','BsmtFinSF1','BsmtFinSF2','BsmtUnfSF','TotalBsmtSF',\n         'BsmtFullBath','BsmtHalfBath','MasVnrArea']\n\nfor zero in zeros:\n    df[zero].fillna(0, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Counter(df.Utilities)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop('Utilities',axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"freq = ['MSZoning','Exterior1st','Exterior2nd','SaleType','Electrical','KitchenQual','Functional']\n\nfor fr in freq:\n    df[fr].fillna(df[fr].mode()[0], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['old_lotfrontage'] = df['LotFrontage']\n\ndf['LotFrontage'] = df.groupby(['LotArea','Neighborhood'])['LotFrontage'].transform(lambda x: x.fillna(x.median()))\ndf['LotFrontage'] = df.groupby('Neighborhood')['LotFrontage'].transform(lambda x: x.fillna(x.median()))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, (ax1,ax2) = plt.subplots(1,2,figsize=(15,5))\nol = sns.distplot(df['old_lotfrontage'].dropna(),ax=ax1,kde=True,bins=70)\nlf = sns.distplot(df['LotFrontage'],ax=ax2,kde=True,bins=70,color='red')\n\n# drop the old_lotfrontage as we finished the comparison\ndf.drop('old_lotfrontage',axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# get_dummies can convert data to 0 and 1 only if the data type is string. Among the many nominal features,\n# MSSubClass, MoSold, and YrSold are integer type so we need to convert them to string type.\n\ndf['MoSold'] = df.astype(str)\ndf['YrSold'] = df.astype(str)\ndf['MSSubClass'] = df.astype(str)\n\nnominals = ['MSSubClass','MSZoning','Street','Alley','LandContour','LotConfig','Neighborhood','Condition1','Condition2','BldgType','HouseStyle','RoofStyle','RoofMatl',\n           'Exterior1st','Exterior2nd','MasVnrType','Foundation','Heating','CentralAir','GarageType','MiscFeature','SaleType','SaleCondition','MoSold','YrSold']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\nordinals = ['LotShape','LandSlope','OverallQual','OverallCond','ExterQual','ExterCond','BsmtQual',\n           'BsmtCond','BsmtExposure','BsmtFinType1','BsmtFinType2','HeatingQC','Electrical','KitchenQual',\n            'Functional','FireplaceQu','GarageFinish','GarageQual','GarageCond','PavedDrive','PoolQC','Fence']\n\nfor ordinal in ordinals:\n    le = LabelEncoder()\n    le.fit(df[ordinal])\n    df[ordinal] = le.transform(df[ordinal])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Total square feet of houses\n\ndf['totalArea'] = df['GrLivArea'] + df['TotalBsmtSF']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Assign numeric features by excluding non numeric features\nnumeric = df.dtypes[df.dtypes != 'object'].index\n\n# Display the skewness of each column and sort the values in descending order \nskewness = df[numeric].apply(lambda x: x.skew()).sort_values(ascending=False)\n\n# Create a dataframe and show 5 most skewed features \nsk_df = pd.DataFrame(skewness,columns=['skewness'])\nsk_df['skw'] = abs(sk_df)\nsk_df.sort_values('skw',ascending=False).drop('skw',axis=1).head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_set.drop('PoolQC',axis=1,inplace = True)\ntrain_set.drop('MiscVal',axis=1,inplace = True)\ndf = pd.get_dummies(df)\nprint(df.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeRegressor","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Split the combined dataset into two: train and test\nkf = KFold(n_splits=3)\nkf.get_n_splits(train_set)\n\nfrom sklearn.model_selection import KFold\nimport xgboost\n#added some parameters\nkf = KFold(n_splits = 5, shuffle = True, random_state = 2)\nmodels = []\nfor i in range(5):\n    result = next(kf.split(df[:train_set.shape[0]]), None)\n    X_train = df[:train_set.shape[0]].iloc[result[0]]\n    X_test =  df[:train_set.shape[0]].iloc[result[1]]\n    y_train = y_df.iloc[result[0]]\n    y_test = y_df.iloc[result[1]]\n    train_id = X_train.iloc[:,0]\n    test_id = X_test.iloc[:,0]\n    X_train.drop('Id',axis=1,inplace = True)\n    X_test.drop('Id',axis=1,inplace = True)\n    scaler = preprocessing.StandardScaler().fit(X_train)\n    scaler.transform(X_train) \n    scaler.transform(X_test)\n    \n    xgb = xgboost.XGBRegressor(n_estimators=100, learning_rate=0.08, gamma=0, subsample=0.75,\n                           colsample_bytree=1, max_depth=10)#learning_rate = 0.08\n    \n    xgb.fit(X_train, y_train)\n    # Fit regression model - Decision Tree Regressor\n    #regr_1 = DecisionTreeRegressor(max_depth=2)\n    #regr_2 = DecisionTreeRegressor(max_depth=10)\n    #regr_1.fit(X_train, y_train)\n    #regr_2.fit(X_train, y_train)\n    #models.append(regr_2)\n    # Predict\n    #X_test = np.arange(0.0, 5.0, 0.01)[:, np.newaxis]\n    #y_1 = regr_1.predict(X_test)\n    #y_2 = regr_2.predict(X_test)\n    y_1 = xgb.predict(X_test)\n    # Plot the results\n    plt.figure()\n    plt.scatter(y_1, y_test)\n    #plt.scatter(X_train, y_train)#, s=20, edgecolor=\"black\",c=\"darkorange\", label=\"data\")\n    #plt.plot(X_test, y_test, color=\"cornflowerblue\",label=\"max_depth=2\", linewidth=2)\n    #plt.plot(X_test, y_test, color=\"yellowgreen\", label=\"max_depth=5\", linewidth=2)\n    #plt.xlabel(\"data\")\n    #plt.ylabel(\"target\")\n    #plt.title(\"Decision Tree Regression\")\n    #plt.legend()\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test = df[train_set.shape[0]:]\ndf_test.drop('Id',axis=1,inplace = True)\ndf_test.shape\ntest_predictions = xgb.predict(df_test)#.flatten()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.DataFrame({\n       \"Id\": ids,\n       \"SalePrice\": test_predictions})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv('house_price 2.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}